epoch：训练时，所有训练数据集都训练过一次。

batch_size：在训练集中选择一组样本用来更新权值。1个batch包含的样本的数目，通常设为2的n次幂，常用的包括64,128,256。 网络较小时选用256，较大时选用64。

iteration?：训练时，1个batch训练图像通过网络训练一次?（一次前向传播+一次后向传播），每迭代一次权重更新一次；测试时，1个batch测试图像通过网络一次?（一次前向传播）。
	所谓iterations就是完成一次epoch所需的batch个数
示例：
每个 Epoch 要训练的图片数量：50000
训练集具有的 Batch 个数：50000 / 256 = 195 + 1 = 196
每个 Epoch 需要完成的 Batch 个数：196
每个 Epoch 具有的 Iteration 个数：196
每个 Epoch 中发生模型权重更新的次数：196
训练 10 代后，模型权重更新的次数：196 * 10 = 1960
不同代的训练，其实用的是同一个训练集的数据。第 1 代和第 10 代虽然用的都是训练集的五万张图片，但是对模型的权重更新值却是完全不同的。
因为不同代的模型处于代价函数空间上的不同位置，模型的训练代越靠后，越接近谷底，其代价越小。